import streamlit as st
from dotenv import load_dotenv
import os

# è¼‰å…¥ LLM æœå‹™å’Œå·¥å…·æ¨¡çµ„
from tools.llm_services import get_llm_client, AVAILABLE_MODELS, LLMClientInterface
from tools import continuous_binning, boolean_tagging

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# --- å´é‚Šæ¬„ ---
st.sidebar.title("ğŸ› ï¸ Tableau å°å·¥å…·ç®±")

# --- LLM è¨­å®š ---
st.sidebar.header("LLM è¨­å®š")
# éæ¿¾æ‰æ²’æœ‰è¨­å®š API Key çš„æä¾›è€…
available_providers = []
if os.getenv("OPENAI_API_KEY"): available_providers.append("OpenAI")
if os.getenv("GEMINI_API_KEY"): available_providers.append("Gemini")
if os.getenv("ANTHROPIC_API_KEY"): available_providers.append("Claude")

if not available_providers:
    st.sidebar.warning("è«‹åœ¨ .env æª”æ¡ˆä¸­è¨­å®šè‡³å°‘ä¸€å€‹ LLM çš„ API Key (ä¾‹å¦‚ OPENAI_API_KEY)ã€‚")
    selected_provider = None
    llm_client = None
else:
    selected_provider = st.sidebar.selectbox(
        "é¸æ“‡ LLM æä¾›è€…:",
        available_providers,
        index=0 # é è¨­é¸ç¬¬ä¸€å€‹å¯ç”¨çš„
    )
    # æ ¹æ“šé¸æ“‡çš„æä¾›è€…é¡¯ç¤ºå¯ç”¨æ¨¡å‹
    if selected_provider:
        models_for_provider = AVAILABLE_MODELS.get(selected_provider.lower(), [])
        if models_for_provider:
            selected_model = st.sidebar.selectbox("é¸æ“‡æ¨¡å‹:", models_for_provider)
        else:
            st.sidebar.warning(f"æ‰¾ä¸åˆ° {selected_provider} çš„å¯ç”¨æ¨¡å‹è¨­å®šã€‚")
            selected_model = None
        
        # ç²å– LLM å®¢æˆ¶ç«¯
        llm_client = get_llm_client(selected_provider)
        if not llm_client:
            st.sidebar.error(f"ç„¡æ³•åˆå§‹åŒ– {selected_provider} å®¢æˆ¶ç«¯ï¼Œè«‹æª¢æŸ¥ API Key æˆ–ç¶²è·¯é€£ç·šã€‚")

    else:
        llm_client = None
        selected_model = None

st.sidebar.markdown("---") # åˆ†éš”ç·š

# --- å·¥å…·é¸æ“‡ ---
st.sidebar.header("é¸æ“‡å·¥å…·")
tool_options = {
    "é€£çºŒå€¼åˆ†çµ„": continuous_binning.show,
    "æ˜¯å¦æ¨™ç±¤": boolean_tagging.show,
    # æœªä¾†å¯ä»¥ç¹¼çºŒå¢åŠ å·¥å…·...
}
selected_tool_name = st.sidebar.radio("é¸æ“‡å·¥å…·ï¼š", list(tool_options.keys()))

# --- ä¸»ç•«é¢ ---
st.markdown(f"#### å·¥å…·ï¼š {selected_tool_name}")

# åŸ·è¡Œé¸æ“‡çš„å·¥å…·å‡½æ•¸
selected_tool_func = tool_options[selected_tool_name]

# åˆ¤æ–·å·¥å…·æ˜¯å¦éœ€è¦ LLM client
# (å¯ä»¥åœ¨å·¥å…·æ¨¡çµ„ä¸­å®šç¾©ä¸€å€‹å±¬æ€§æˆ–å‡½æ•¸ä¾†æ¨™ç¤ºï¼Œæˆ–åœ¨é€™è£¡ç¡¬ç·¨ç¢¼åˆ¤æ–·)
tool_requires_llm = (selected_tool_name == "é€£çºŒå€¼åˆ†çµ„") # å‡è¨­ç›®å‰åªæœ‰å®ƒéœ€è¦

if tool_requires_llm:
    if llm_client and selected_model:
        # å°‡é€šç”¨çš„ client å’Œé¸å®šçš„ model å‚³éçµ¦å·¥å…·
        selected_tool_func(llm_client, selected_model)
    elif not selected_provider:
         st.error("è«‹å…ˆåœ¨å´é‚Šæ¬„è¨­å®šæœ‰æ•ˆçš„ LLM æä¾›è€…åŠ API Keyã€‚")
    elif not llm_client:
        st.error(f"ç„¡æ³•è¼‰å…¥ {selected_provider} çš„ LLM æœå‹™ï¼Œè«‹æª¢æŸ¥å´é‚Šæ¬„éŒ¯èª¤è¨Šæ¯ã€‚")
    else: # llm_client æœ‰ï¼Œä½† selected_model æ²’æœ‰ (ç†è«–ä¸Šä¸å¤ªæœƒç™¼ç”Ÿ)
        st.error("è«‹åœ¨å´é‚Šæ¬„é¸æ“‡ä¸€å€‹æ¨¡å‹ã€‚")
else:
    # å°æ–¼ä¸éœ€è¦ LLM çš„å·¥å…·
    selected_tool_func()

